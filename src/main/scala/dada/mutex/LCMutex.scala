package dada.mutex

import dada.detail.{TAck, TLogicalClock}
import dada.clock.LogicalClock
import dada.Config._

import dds._
import dds.config.DefaultEntities.{defaultDomainParticipant, defaultPolicyFactory}
import dds.prelude._
import java.util.concurrent.Semaphore
import java.util.concurrent.atomic.{AtomicReference, AtomicLong}
import dada.group.Group
import dada.concurrent.synchronisers._
import scala.collection.JavaConversions._
import dada.clock.LogicalClock._

object LCMutex {
  val mutexRequestTopic = Topic[TLogicalClock]("MutexRequest")
  val mutexAckTopic = Topic[TAck]("MutexAck")
  private var subMap = Map[Int, org.omg.dds.sub.Subscriber]()
  private var pubMap = Map[Int, org.omg.dds.pub.Publisher]()

  import dds.config.DefaultEntities.{defaultPub, defaultSub}
  val drQos = DataReaderQos().withPolicies(
    History.KeepAll,
    Reliability.Reliable
  )
  val dwQos = DataWriterQos().withPolicies(
    History.KeepAll,
    Reliability.Reliable
  )


  def groupPublisher(gid: Int): org.omg.dds.pub.Publisher = synchronized {
    pubMap.getOrElse(gid, {
      val qos = PublisherQos().withPolicy(
        Partition(gid.toString)
      )
      val pub = Publisher(mutexRequestTopic.getParent(), qos)
      pubMap = pubMap + (gid -> pub)
      pub
    })
  }

  def groupSubscriber(gid: Int): org.omg.dds.sub.Subscriber = synchronized {
    subMap getOrElse(gid, {
      val qos = SubscriberQos().withPolicy(
        Partition(gid.toString)
      )
      val sub = Subscriber(mutexRequestTopic.getParent(), qos)
      subMap = subMap + (gid -> sub)
      sub
    })
  }

}
/**
 * This is a distributed Mutex implemented levaraging Lamports logical clock algorithm.
 * To be precise the obvious Agrawal optimization on Lamport algorithms is implemented
 * so to use the ACK as a "release".
 *
 * To properly separate the protocol traffic generated by independent Mutex each group
 * runs in its own partition.
 *
 * <b>NOTE:</b> This mutex object is single threaded, meaning that no concurrent
 * acquire release should be issued. In addition notice that this version of the
 * algorithm is not fault-tolerant.
 *
 * @author <a href="mailto:angelo@icorsaro.net">Angelo Corsaro</a>
 * @author <a href="mailto:sara@icorsaro.net">Sara Tucci</a>
 *
 * @version 0.1
 *
 * @param mid the member id
 * @param gid the group id associated with this mutex
 */
class LCMutex(val mid: Int, val gid: Int)(implicit val logger: Logger) extends Mutex {

  private val group = Group(gid)
  private val tsRef = new AtomicReference[LogicalClock](LogicalClock(0, mid))
  private val receivedAcks = new AtomicLong(0)

  private val pendingRequestsRef = new AtomicReference[List[LogicalClock]](List[LogicalClock]())
  private var myRequest =  LogicalClock.Infinite

  private val reqDW = DataWriter[TLogicalClock](LCMutex.groupPublisher(gid), LCMutex.mutexRequestTopic, LCMutex.dwQos)
  private val reqDR = DataReader[TLogicalClock](LCMutex.groupSubscriber(gid), LCMutex.mutexRequestTopic, LCMutex.drQos)

  private val ackDW = DataWriter[TAck](LCMutex.groupPublisher(gid), LCMutex.mutexAckTopic, LCMutex.dwQos)
  private val ackDR = DataReader[TAck](LCMutex.groupSubscriber(gid), LCMutex.mutexAckTopic, LCMutex.drQos)
  private val ackSemaphore = new Semaphore(0)


  ackDR listen {
    case DataAvailable(dr) => {
      // Count only the ACK for us
      val acks = ackDR.take.toList filter (s => s.getData != null && s.getData.amid == mid)
      val k = acks.length

      if (acks.nonEmpty) {
        // Set the local clock to the max (tsi, tsj) + 1
        compareAndSet(tsRef) {ts =>
          val maxTs = math.max(ts.ts, (acks map (_.getData.ts.ts)).max) + 1
          LogicalClock(maxTs, ts.id)
        }

        val ra = receivedAcks.addAndGet(k)
        val groupSize = group.size
        logger.trace(Console.BLUE +"M" + mid + " received " + ra +" Acks" + Console.RESET)
        logger.trace(Console.BLUE +"M" + mid + " estimated group size: " + groupSize + Console.RESET)
        // If received sufficient many ACKs we can enter our Mutex!
        if (ra == groupSize - 1) {
          receivedAcks.set(0)
          ackSemaphore.release()
        }
      }
    }
  }

  reqDR listen{
    case DataAvailable(dr) => {

      val requests = reqDR.take.toList
        .filter(_.getData != null)
        .map (_.getData)
        .filterNot(_.mid == mid)

      if (requests.nonEmpty) {
        compareAndSet(tsRef) {ts =>
          val maxTs = math.max(ts.ts, (requests map (_.ts)).max) + 1
          LogicalClock(maxTs, ts.id)
        }

        requests foreach (r => {
          if (r < myRequest) {
            compareAndSet(tsRef) { ts => ts inc() }
            val ack = new TAck(r.mid, tsRef.get)
            logger.trace(Console.GREEN +"M."+mid + "  sending ACKs = P"+r.mid +" wiht  TS = " + tsRef.get + Console.RESET)
            ackDW write ack
            None
          }
          else
          // We need atomicity here to avoid loosing requests
            compareAndSet(pendingRequestsRef) { pendingRequests =>
             if (pendingRequests.contains(r)) pendingRequests else (r :: pendingRequests)
            }

        })
        logger.trace(Console.YELLOW + "-----------------------------------" + Console.RESET)
        logger.trace(Console.YELLOW + "[M."+ mid +"]: Un-Acked Requests Queue" + Console.RESET)
        pendingRequestsRef.get foreach (r => logger.trace(r.toString))
        logger.trace(Console.YELLOW + "-----------------------------------" + Console.RESET)
        logger.trace(Console.RED + "[M."+ mid +"]: MUTEX onReq Exit" + Console.RESET)
      }
    }
  }

  def acquire() {
    compareAndSet(tsRef) { ts => ts.inc() }

    myRequest = tsRef.get()
    logger.trace(Console.RED + "[M."+ mid +"]: ACQUIRE REQ with ts = " + myRequest + Console.RESET)
    reqDW write myRequest

    // Try to acquire the semaphore and re-issue a request if timeout
    // The assumption is that the system stabilize within the timeout
    // and if we've not received all the ACKS than someone has crashed...
    // Thus we re-try....
    ackSemaphore.acquire()
    logger.trace(Console.RED + "[M."+ mid +"]: Mutex ACQUIRED with ts = " + myRequest + Console.RESET)

  }

  def release() {
    logger.trace(Console.GREEN + "[M."+ mid +"]: Mutex RELEASE" + Console.RESET)
    myRequest = LogicalClock.Infinite

    // The Mutex is single threaded, thus non need to be atomic.
    val pendingRequests = pendingRequestsRef.get
      pendingRequests.foreach { req =>
        logger.trace(Console.GREEN + "M." + mid + "  sending ACKs = M." + req.id + " wiht  TS = " + tsRef.get + Console.RESET)
        ackDW write (new TAck(req.id, tsRef.get))
      }
      pendingRequestsRef.set(List())
  }
}
